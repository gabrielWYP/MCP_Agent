{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c732fdb4",
   "metadata": {},
   "source": [
    "# Prototipo de Agente Orquestador de MLOps con LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f487d6",
   "metadata": {},
   "source": [
    "## 1. Instalación e Importaciones\n",
    "\n",
    "Instalamos las dependencias y luego importamos los módulos necesarios. Importamos nuestras funciones de nodos desde el archivo `utils.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde42d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Añadimos el directorio actual al path para poder importar nuestro módulo de utilidades\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Importamos el estado y todas las funciones de los nodos desde utils.py\n",
    "from notebooks.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bbe766",
   "metadata": {},
   "source": [
    "## 2. Definición de las Aristas Condicionales\n",
    "\n",
    "Las aristas condicionales nos permiten crear ramas en nuestro grafo. La primera (`data_found_check`) decide si continuar el flujo o detenerse si no hay datos nuevos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe44a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_found_check(state: MLOpsState) -> str:\n",
    "    print(\"--- (EDGE) ¿Se encontraron datos nuevos? ---\")\n",
    "    if state.get(\"new_data_path\") == \"NO_NEW_DATA\":\n",
    "        print(\"--> No. Finalizando ejecución.\")\n",
    "        return \"end\"\n",
    "    else:\n",
    "        print(\"--> Sí. Procediendo a validar datos.\")\n",
    "        return \"continue\"\n",
    "\n",
    "def should_train(state: MLOpsState) -> str:\n",
    "    print(\"--- (EDGE) ¿Datos de buena calidad? ---\")\n",
    "    if state.get(\"failure_analysis_report\"):\n",
    "        print(\"--> No. Alertando a humano.\")\n",
    "        return \"alert_human\"\n",
    "    else:\n",
    "        print(\"--> Sí. Procediendo a entrenamiento.\")\n",
    "        return \"run_training_job\"\n",
    "\n",
    "def should_deploy(state: MLOpsState) -> str:\n",
    "    print(\"--- (EDGE) ¿Decisión de despliegue? ---\")\n",
    "    if state.get(\"deployment_decision\") == \"APPROVE\":\n",
    "        print(\"--> APROBADO. Desplegando a producción.\")\n",
    "        return \"deploy_to_production\"\n",
    "    else:\n",
    "        print(\"--> RECHAZADO. Alertando a humano.\")\n",
    "        return \"alert_human\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb8aff",
   "metadata": {},
   "source": [
    "## 3. Construcción y Compilación del Grafo\n",
    "\n",
    "Ensamblamos todos los nodos y aristas importados para construir el grafo ejecutable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b93b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MLOpsState)\n",
    "\n",
    "# Añadir nodos\n",
    "workflow.add_node(\"check_for_new_data\", check_for_new_data)\n",
    "workflow.add_node(\"validate_data\", validate_data)\n",
    "workflow.add_node(\"run_training_job\", run_training_job)\n",
    "workflow.add_node(\"analyze_performance\", analyze_performance)\n",
    "workflow.add_node(\"deploy_to_production\", deploy_to_production)\n",
    "workflow.add_node(\"alert_human\", alert_human)\n",
    "\n",
    "# Definir punto de entrada\n",
    "workflow.set_entry_point(\"check_for_new_data\")\n",
    "\n",
    "# Añadir aristas\n",
    "workflow.add_conditional_edges(\"check_for_new_data\", data_found_check, {\"continue\": \"validate_data\", \"end\": END})\n",
    "workflow.add_conditional_edges(\"validate_data\", should_train, {\"run_training_job\": \"run_training_job\", \"alert_human\": \"alert_human\"})\n",
    "workflow.add_edge(\"run_training_job\", \"analyze_performance\")\n",
    "workflow.add_conditional_edges(\"analyze_performance\", should_deploy, {\"deploy_to_production\": \"deploy_to_production\", \"alert_human\": \"alert_human\"})\n",
    "\n",
    "# Definir puntos finales\n",
    "workflow.add_edge(\"deploy_to_production\", END)\n",
    "workflow.add_edge(\"alert_human\", END)\n",
    "\n",
    "# Compilar el grafo\n",
    "app = workflow.compile()\n",
    "print(\"Grafo compilado y listo para usar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dff2a9",
   "metadata": {},
   "source": [
    "## 4. Ejecución del Grafo\n",
    "\n",
    "Ahora podemos invocar el grafo. Si no tienes configurado un bucket, el primer nodo fallará de forma segura y terminará el ciclo. Si creas un bucket y una carpeta `new`, puedes probar el flujo completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199232a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para probar, puedes crear un archivo .env en la raíz del proyecto con tus credenciales:\n",
    "# S3_ENDPOINT_URL=https://<tu-endpoint>\n",
    "# S3_ACCESS_KEY=<tu-access-key>\n",
    "# S3_SECRET_KEY=<tu-secret-key>\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "initial_state = {\"model_version\": 2} \n",
    "final_state = app.invoke(initial_state)\n",
    "\n",
    "print(\"--- ESTADO FINAL DEL GRAFO ---\")\n",
    "print(final_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
